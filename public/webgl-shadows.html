<p>Title: WebGL2 Shadows<br />Description: How to compute shadows<br />TOC: Shadows</p>

<p>Lets draw some shadows!</p>

<h2>Prerequisites</h2>

<p>Computing basic shadows is not <em>that</em> hard but it does require<br />a lot of background knowledge. To understand this article<br />you need to already understand the following topics.</p>

<ul>
<li><a href="webgl-3d-orthographic.html">Orthographic Projection</a></li>
<li><a href="webgl-3d-perspective.html">Perspective Projection</a></li>
<li><a href="webgl-3d-lighting-spot.html">Spot Lighting</a></li>
<li><a href="webgl-3d-textures.html">Textures</a></li>
<li><a href="webgl-render-to-texture.html">Render to Texture</a></li>
<li><a href="webgl-planar-projection-mapping.html">Projecting textures</a></li>
<li><a href="webgl-visualizing-the-camera.html">Visualizing the Camera</a></li>
</ul>

<p>So if you haven't read those please go read them first.</p>

<p>On top of that this article assumes you've read the article on<br /><a href="webgl-less-code-more-fun.html">less code more fun</a><br />as it uses the library mentioned there so as to<br />unclutter the example. If you don't understand<br />what buffers, vertex arrays, and attributes are or when<br />a function named <code>twgl.setUniforms</code> what it means<br />to set uniforms, etc... then you should probably to go further back and<br /><a href="webgl-fundamentals.html">read the fundamentals</a>.</p>

<p>So first off there is more than one way to draw shadows.<br />Every way has it's tradeoffs. The most common way to draw<br />shadows is to use shadow maps</p>

<p>Shadow maps work by combining the techniques from all the prerequisite<br />articles above.</p>

<p>In <a href="webgl-planar-projection-mapping.html">the article on planar projection mapping</a><br />we saw how to project an image on to objects</p>

<p>{{{example url="../webgl-planar-projection-with-projection-matrix.html"}}}</p>

<p>Recall that we didn't draw that image on top of the objects in the scene,<br />rather, as the objects were rendered, for each pixel we checked if the<br />projected texture was in range, if so we sampled the appropriate color from<br />the projected texture, if not we sampled a color from a different texture<br />who's color was looked up using texture coordinates that mapped a texture<br />to the object.</p>

<p>What if the projected texture instead contained depth data from the point<br />of view of a light. In other words assume there was a light at the tip of<br />the frustum shown in that example above and the projected texture had depth<br />info from the light's point of view. The sphere would have depth values closer<br />to the light, the plane would have depth values further<br />from the light. </p>

<div class="webgl_center"><img class="noinvertdark" src="resources/depth-map-generation.svg" style="width: 600px;"></div>

<p>If we had that data then when choosing a color to render<br />we could get a depth value from the projected texture and check if the<br />depth of the pixel we're about to draw is closer or further from the light.<br />If it's further from the light that<br />means something was else was closer to the light. In other words,<br />something is blocking the light, therefore this pixel is in a shadow.</p>

<div class="webgl_center"><img class="noinvertdark" src="resources/projected-depth-texture.svg" style="width: 600px;"></div>

<p>Here the depth texture is projected through light space inside the frustum from the point of view of the light.<br />When we are drawing the pixels of the floor we compute that pixel's depth from the point of view <br />of the light (0.3 in the diagram above). We then look at the corresponding depth in<br />the projected depth map texture. From the point of view of the light the depth value<br />in the texture will be 0.1 because it hit the sphere. Seeing that 0.1 &lt; 0.3 we<br />know the floor at that position must be in shadow.</p>

<p>First let's draw the shadow map. We'll take the last example from<br /><a href="webgl-planar-projection-mapping.html">the article on planar projection mapping</a><br />but instead of loading a texture we'll <a href="webgl-render-to-texture.html">render to a texture</a><br />so we create a depth texture and attach it to a framebuffer as the <code>DEPTH_ATTACHMENT</code>.</p>

<pre><code>
const depthTexture = gl.createTexture();
const depthTextureSize = 512;
gl.bindTexture(gl.TEXTURE_2D, depthTexture);
gl.texImage2D(
    gl.TEXTURE_2D,      // target
    0,                  // mip level
    gl.DEPTH_COMPONENT32F, // internal format
    depthTextureSize,   // width
    depthTextureSize,   // height
    0,                  // border
    gl.DEPTH_COMPONENT, // format
    gl.FLOAT,           // type
    null);              // data
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);

const depthFramebuffer = gl.createFramebuffer();
gl.bindFramebuffer(gl.FRAMEBUFFER, depthFramebuffer);
gl.framebufferTexture2D(
    gl.FRAMEBUFFER,       // target
    gl.DEPTH_ATTACHMENT,  // attachment point
    gl.TEXTURE_2D,        // texture target
    depthTexture,         // texture
    0);                   // mip level
</code></pre>

<p>To use it we need to able to render the scene more than once with different<br />shaders. Once with a simple shader just to render to the depth texture and<br />then again with our current shader that projects a texture.</p>

<p>So first let's change <code>drawScene</code> so we can pass it the program we want<br />to render with</p>

<pre><code>
-function drawScene(projectionMatrix, cameraMatrix, textureMatrix) {
+function drawScene(projectionMatrix, cameraMatrix, textureMatrix, programInfo) {
  // Make a view matrix from the camera matrix.
  const viewMatrix = m4.inverse(cameraMatrix);

-  gl.useProgram(textureProgramInfo.program);
+  gl.useProgram(programInfo.program);

  // set uniforms that are the same for both the sphere and plane
  // note: any values with no corresponding uniform in the shader
  // are ignored.
-  twgl.setUniforms(textureProgramInfo, {
+  twgl.setUniforms(programInfo, {
    u_view: viewMatrix,
    u_projection: projectionMatrix,
*    u_textureMatrix: textureMatrix,
-    u_projectedTexture: imageTexture,
+    u_projectedTexture: depthTexture,
  });

  // ------ Draw the sphere --------

  // Setup all the needed attributes.
  gl.bindVertexArray(sphereVAO);

  // Set the uniforms unique to the sphere
-  twgl.setUniforms(textureProgramInfo, sphereUniforms);
+  twgl.setUniforms(programInfo, sphereUniforms);

  // calls gl.drawArrays or gl.drawElements
  twgl.drawBufferInfo(gl, sphereBufferInfo);

  // ------ Draw the plane --------

  // Setup all the needed attributes.
  gl.bindVertexArray(planeVAO);

  // Set the uniforms we just computed
-  twgl.setUniforms(textureProgramInfo, planeUniforms);
+  twgl.setUniforms(programInfo, planeUniforms);

  // calls gl.drawArrays or gl.drawElements
  twgl.drawBufferInfo(gl, planeBufferInfo);
}
</code></pre>

<p>Now that we're going to be using the same vertex arrays with multiple<br />shader programs we need to make sure those programs use the same attributes.<br />This was brought up before when talking about vertex arrays (VAOs in the code above)<br />but I think this is the first example on this site that actually runs into this<br />issue. In other words we're going to draw the sphere and the plane with both<br />the projected texture shader program and the solid color shader program.<br />The projected texture shader program has 2 attributes, <code>a_position</code> and<br /><code>a_texcoord</code>. The solid color shader program just was one, <code>a_position</code>.<br />If we don't tell WebGL what attribute locations to use it's possible<br />it would <code>a_position</code> location = 0 for shader and location = 1 for the other<br />(or really WebGL could pick any arbitrary location). If that happens<br />then the attributes we setup in <code>sphereVAO</code> and <code>planeVAO</code> won't match<br />both programs. </p>

<p>We can solve this 2 ways.</p>

<ol>
<li><p>In GLSL add <code>layout(location = 0)</code> in front of each attribute </p>

<div class="highlight"><pre lang="glsl">layout(location = 0) in vec4 a_position;
layout(location = 1) in vec4 a_texcoord;
</pre></div>

<p>If we had 150 shaders we'd have to repeat those locations across all of them<br />and track which shaders use which locations</p></li>
<li><p>call <code>gl.bindAttribLocation</code> before linking shaders</p>

<p>In this case before we call <code>gl.linkProgram</code> we'd call <code>gl.bindAttribLocation</code>.<br />(see <a href="webgl-fundamentals.html">first article</a>)</p>

<div class="highlight"><pre lang="js">gl.bindAttribLocation(program, 0, "a_position");
gl.bindAttribLocation(program, 1, "a_texcoord");
gl.linkProgram(program);
...
</pre></div></li>
</ol>

<p>We'll use this second way since it's more <a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">D.R.Y</a></p>

<p>The library we're using to compile and link our shaders as the option to do this<br />for us. We just pass it the names of the attributes and their locations and it<br />will call <code>gl.bindAttribLocation</code> for us</p>

<pre><code>
// setup GLSL programs
+// note: Since we're going to use the same VAO with multiple
+// shader programs we need to make sure all programs use the
+// same attribute locations. There are 2 ways to do that.
+// (1) assign them in GLSL. (2) assign them by calling `gl.bindAttribLocation`
+// before linking. We're using method 2 as it's more. D.R.Y.
+const programOptions = {
+  attribLocations: {
+    'a_position': 0,
+    'a_normal':   1,
+    'a_texcoord': 2,
+    'a_color':    3,
+  },
+};
-const textureProgramInfo = twgl.createProgramInfo(gl, [vs, fs]);
-const colorProgramInfo = twgl.createProgramInfo(gl, [colorVS, colorFS],);
+const textureProgramInfo = twgl.createProgramInfo(gl, [vs, fs], programOptions);
+const colorProgramInfo = twgl.createProgramInfo(gl, [colorVS, colorFS], programOptions);
</code></pre>

<p>Now let's use <code>drawScene</code> to draw the scene from the point of view of the light<br />and then again with the depth texture</p>

<pre><code>
function render() {
  twgl.resizeCanvasToDisplaySize(gl.canvas);

  gl.enable(gl.CULL_FACE);
  gl.enable(gl.DEPTH_TEST);

  // first draw from the POV of the light
-  const textureWorldMatrix = m4.lookAt(
+  const lightWorldMatrix = m4.lookAt(
      [settings.posX, settings.posY, settings.posZ],          // position
      [settings.targetX, settings.targetY, settings.targetZ], // target
      [0, 1, 0],                                              // up
  );
-  const textureProjectionMatrix = settings.perspective
+  const lightProjectionMatrix = settings.perspective
      ? m4.perspective(
          degToRad(settings.fieldOfView),
          settings.projWidth / settings.projHeight,
          0.5,  // near
          10)   // far
      : m4.orthographic(
          -settings.projWidth / 2,   // left
           settings.projWidth / 2,   // right
          -settings.projHeight / 2,  // bottom
           settings.projHeight / 2,  // top
           0.5,                      // near
           10);                      // far

+  // draw to the depth texture
+  gl.bindFramebuffer(gl.FRAMEBUFFER, depthFramebuffer);
+  gl.viewport(0, 0, depthTextureSize, depthTextureSize);
+  gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

-  drawScene(textureProjectionMatrix, textureWorldMatrix, m4.identity());
+  drawScene(lightProjectionMatrix, lightWorldMatrix, m4.identity(), colorProgramInfo);

+  // now draw scene to the canvas projecting the depth texture into the scene
+  gl.bindFramebuffer(gl.FRAMEBUFFER, null);
+  gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
+  gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

  let textureMatrix = m4.identity();
  textureMatrix = m4.translate(textureMatrix, 0.5, 0.5, 0.5);
  textureMatrix = m4.scale(textureMatrix, 0.5, 0.5, 0.5);
-  textureMatrix = m4.multiply(textureMatrix, textureProjectionMatrix);
+  textureMatrix = m4.multiply(textureMatrix, lightProjectionMatrix);
  // use the inverse of this world matrix to make
  // a matrix that will transform other positions
  // to be relative this this world space.
  textureMatrix = m4.multiply(
      textureMatrix,
-      m4.inverse(textureWorldMatrix));
+      m4.inverse(lightWorldMatrix));

  // Compute the projection matrix
  const aspect = gl.canvas.clientWidth / gl.canvas.clientHeight;
  const projectionMatrix =
      m4.perspective(fieldOfViewRadians, aspect, 1, 2000);

  // Compute the camera's matrix using look at.
  const cameraPosition = [settings.cameraX, settings.cameraY, 7];
  const target = [0, 0, 0];
  const up = [0, 1, 0];
  const cameraMatrix = m4.lookAt(cameraPosition, target, up);

-  drawScene(projectionMatrix, cameraMatrix, textureMatrix); 
+  drawScene(projectionMatrix, cameraMatrix, textureMatrix, textureProgramInfo); 
}
</code></pre>

<p>Note I renamed <code>textureWorldMatrix</code> to <code>lightWorldMatrix</code> and<br /><code>textureProjectionMatrix</code> to <code>lightProjectionMatrix</code>. They are really the<br />same thing but before we were projecting a texture through arbitrary space.<br />Now we're trying to project a shadow map from a light. The math is the same<br />but it seemed appropriate to rename the variables.</p>

<p>Above we first render the sphere and the plane to the depth texture<br />using the color shader we made to draw the frustum lines. That shader<br />just draws a solid color and does nothing else special which is all<br />we need when rendering to the depth texture.</p>

<p>After that, we render the scene again to the canvas just as we did before,<br />projecting the texture into the scene. <br />When we reference the depth texture in a shader only the red<br />value is valid so we'll just repeat it for red, green, and blue.</p>

<pre><code>
void main() {
  vec3 projectedTexcoord = v_projectedTexcoord.xyz / v_projectedTexcoord.w;
  bool inRange = 
      projectedTexcoord.x >= 0.0 &&
      projectedTexcoord.x <= 1.0 &&
      projectedTexcoord.y >= 0.0 &&
      projectedTexcoord.y <= 1.0;

-  vec4 projectedTexColor = texture2D(u_projectedTexture, projectedTexcoord.xy);
+  // the 'r' channel has the depth values
+  vec4 projectedTexColor = vec4(texture2D(u_projectedTexture, projectedTexcoord.xy).rrr, 1);
  vec4 texColor = texture2D(u_texture, v_texcoord) * u_colorMult;
  float projectedAmount = inRange ? 1.0 : 0.0;
  gl_FragColor = mix(texColor, projectedTexColor, projectedAmount);
}
</code></pre>

<p>While we're at it let's add a cube to the scene</p>

<pre><code>
+const cubeBufferInfo = twgl.primitives.createCubeBufferInfo(
+    gl,
+    2,  // size
+);

...

+const cubeUniforms = {
+  u_colorMult: [0.5, 1, 0.5, 1],  // light green
+  u_color: [0, 0, 1, 1],
+  u_texture: checkerboardTexture,
+  u_world: m4.translation(3, 1, 0),
+};

...

function drawScene(projectionMatrix, cameraMatrix, textureMatrix, programInfo) {

    ...

+    // ------ Draw the cube --------
+
+    // Setup all the needed attributes.
+    gl.bindVertexArray(cubeVAO);
+
+    // Set the uniforms we just computed
+    twgl.setUniforms(programInfo, cubeUniforms);
+
+    // calls gl.drawArrays or gl.drawElements
+    twgl.drawBufferInfo(gl, cubeBufferInfo);

...
</code></pre>

<p>and let's tweak the settings. We'll move the camera<br />and widen the field of view for the texture projection to cover more of the scene</p>

<pre><code>
const settings = {
-  cameraX: 2.5,
+  cameraX: 6,
  cameraY: 5,
  posX: 2.5,
  posY: 4.8,
  posZ: 4.3,
  targetX: 2.5,
  targetY: 0,
  targetZ: 3.5,
  projWidth: 1,
  projHeight: 1,
  perspective: true,
-  fieldOfView: 45,
+  fieldOfView: 120,
};
</code></pre>

<p>note: I moved the code that draws the line cube that shows the<br />frustum outside of the <code>drawScene</code> function.</p>

<p>{{{example url="../webgl-shadows-depth-texture.html"}}}</p>

<p>This is exactly the same as the top example except instead<br />of loading an image we're generating a depth texture by<br />rendering the scene to it. If you want to verify adjust <code>cameraX</code><br />back to 2.5 and <code>fieldOfView</code> to 45 and it should look the same<br />as above except with our new depth texture being projected<br />instead of a loaded image.</p>

<p>Depth values go from 0.0 to 1.0 representing their position<br />through the frustum so 0.0 (dark) is close to the tip<br />of the frustum and 1.0 (light) is at the far open end.</p>

<p>So all that's left to do is instead of choosing between our projected<br />texture color and our texture mapped color we can use the depth from<br />the depth texture to check if the Z position from the depth texture<br />is closer or further from the light then the depth of the pixel we're<br />being asked to draw. If the depth from the depth texture is closer than something<br />was blocking the light and this pixel is in a shadow.</p>

<pre><code>
void main() {
  vec3 projectedTexcoord = v_projectedTexcoord.xyz / v_projectedTexcoord.w;
+  float currentDepth = projectedTexcoord.z;

  bool inRange = 
      projectedTexcoord.x >= 0.0 &&
      projectedTexcoord.x <= 1.0 &&
      projectedTexcoord.y >= 0.0 &&
      projectedTexcoord.y <= 1.0;

-  vec4 projectedTexColor = vec4(texture(u_projectedTexture, projectedTexcoord.xy).rrr, 1);
+  float projectedDepth = texture(u_projectedTexture, projectedTexcoord.xy).r;
+  float shadowLight = (inRange && projectedDepth <= currentDepth) ? 0.0 : 1.0;  

  vec4 texColor = texture(u_texture, v_texcoord) * u_colorMult;
-  outColor = mix(texColor, projectedTexColor, projectedAmount);
+  outColor = vec4(texColor.rgb * shadowLight, texColor.a);
}
</code></pre>

<p>Above if the <code>projectedDepth</code> is less than the <code>currentDepth</code> then<br />the from the point of view of the light something was closer to<br />the light so this pixel we're about to draw is in shadow.</p>

<p>If we run this we'll get a shadow</p>

<p>{{{example url="../webgl-shadows-basic.html" }}}</p>

<p>It's kind of working, we can see the shadow of the sphere on<br />the ground but what's with all these funky patterns where there<br />is supposed to be no shadow? These patterns<br />are called <em>shadow acne</em>. They come from the fact that the<br />depth data stored in the depth texture has been quantized both<br />in that it's a texture, a grid of pixels, it was projected from the<br />point of view of the light but we're comparing it to values from the<br />the point of view of the camera. That means the grid of values in the<br />depth map is not aligned with our camera and<br />so when we compute <code>currentDepth</code> there are times when one value<br />will be slightly more or slightly less than <code>projectedDepth</code>.</p>

<p>Let's add a bias. </p>

<pre><code>
...

+uniform float u_bias;

void main() {
  vec3 projectedTexcoord = v_projectedTexcoord.xyz / v_projectedTexcoord.w;
-  float currentDepth = projectedTexcoord.z;
+  float currentDepth = projectedTexcoord.z + u_bias;

  bool inRange = 
      projectedTexcoord.x >= 0.0 &&
      projectedTexcoord.x <= 1.0 &&
      projectedTexcoord.y >= 0.0 &&
      projectedTexcoord.y <= 1.0;

  float projectedDepth = texture(u_projectedTexture, projectedTexcoord.xy).r;
  float shadowLight = (inRange && projectedDepth <= currentDepth) ? 0.0 : 1.0;  

  vec4 texColor = texture(u_texture, v_texcoord) * u_colorMult;
  outColor = vec4(texColor.rgb * shadowLight, texColor.a);
}
</code></pre>

<p>And we need to set it</p>

<pre><code>
const settings = {
  cameraX: 2.75,
  cameraY: 5,
  posX: 2.5,
  posY: 4.8,
  posZ: 4.3,
  targetX: 2.5,
  targetY: 0,
  targetZ: 3.5,
  projWidth: 1,
  projHeight: 1,
  perspective: true,
  fieldOfView: 120,
+  bias: -0.006,
};

...

function drawScene(projectionMatrix, cameraMatrix, textureMatrix, programInfo, /**/u_lightWorldMatrix) {
  // Make a view matrix from the camera matrix.
  const viewMatrix = m4.inverse(cameraMatrix);

  gl.useProgram(programInfo.program);

  // set uniforms that are the same for both the sphere and plane
  // note: any values with no corresponding uniform in the shader
  // are ignored.
  twgl.setUniforms(programInfo, {
    u_view: viewMatrix,
    u_projection: projectionMatrix,
+    u_bias: settings.bias,
    u_textureMatrix: textureMatrix,
    u_projectedTexture: depthTexture,
  });

  ...
</code></pre>

<p>{{{example url="../webgl-shadows-basic-w-bias.html"}}}</p>

<p>slide the bias value and you can how it affects when and where<br />the patterns appear.</p>

<p>To get closer to completion this let's actually add in a spot light calculation<br />from <a href="webgl-3d-lighting-spot.html">the article on spot lights</a>.</p>

<p>First let's paste in the needed parts to the vertex shader directly<br />from <a href="webgl-3d-lighting-spot.html">that article</a>.</p>

<pre><code>
#version 300 es
in vec4 a_position;
in vec2 a_texcoord;
+in vec3 a_normal;

+uniform vec3 u_lightWorldPosition;
+uniform vec3 u_viewWorldPosition;

uniform mat4 u_projection;
uniform mat4 u_view;
uniform mat4 u_world;
uniform mat4 u_textureMatrix;

out vec2 v_texcoord;
out vec4 v_projectedTexcoord;
+out vec3 v_normal;

+out vec3 v_surfaceToLight;
+out vec3 v_surfaceToView;

void main() {
  // Multiply the position by the matrix.
  vec4 worldPosition = u_world * a_position;

  gl_Position = u_projection * u_view * worldPosition;

  // Pass the texture coord to the fragment shader.
  v_texcoord = a_texcoord;

  v_projectedTexcoord = u_textureMatrix * worldPosition;

+  // orient the normals and pass to the fragment shader
+  v_normal = mat3(u_world) * a_normal;
+
+  // compute the world position of the surface
+  vec3 surfaceWorldPosition = (u_world * a_position).xyz;
+
+  // compute the vector of the surface to the light
+  // and pass it to the fragment shader
+  v_surfaceToLight = u_lightWorldPosition - surfaceWorldPosition;
+
+  // compute the vector of the surface to the view/camera
+  // and pass it to the fragment shader
+  v_surfaceToView = u_viewWorldPosition - surfaceWorldPosition;
}
</code></pre>

<p>Then the fragment shader</p>

<pre><code>
#version 300 es
precision highp float;

// Passed in from the vertex shader.
in vec2 v_texcoord;
in vec4 v_projectedTexcoord;
+in vec3 v_normal;
+in vec3 v_surfaceToLight;
+in vec3 v_surfaceToView;

uniform vec4 u_colorMult;
uniform sampler2D u_texture;
uniform sampler2D u_projectedTexture;
uniform float u_bias;
+uniform float u_shininess;
+uniform vec3 u_lightDirection;
+uniform float u_innerLimit;          // in dot space
+uniform float u_outerLimit;          // in dot space

out vec4 outColor;

void main() {
+  // because v_normal is a varying it's interpolated
+  // so it will not be a unit vector. Normalizing it
+  // will make it a unit vector again
+  vec3 normal = normalize(v_normal);
+
+  vec3 surfaceToLightDirection = normalize(v_surfaceToLight);
+  vec3 surfaceToViewDirection = normalize(v_surfaceToView);
+  vec3 halfVector = normalize(surfaceToLightDirection + surfaceToViewDirection);
+
+  float dotFromDirection = dot(surfaceToLightDirection,
+                               -u_lightDirection);
+  float limitRange = u_innerLimit - u_outerLimit;
+  float inLight = clamp((dotFromDirection - u_outerLimit) / limitRange, 0.0, 1.0);
+  float light = inLight * dot(normal, surfaceToLightDirection);
+  float specular = inLight * pow(dot(normal, halfVector), u_shininess);

  vec3 projectedTexcoord = v_projectedTexcoord.xyz / v_projectedTexcoord.w;
  float currentDepth = projectedTexcoord.z + u_bias;

  bool inRange =
      projectedTexcoord.x >= 0.0 &&
      projectedTexcoord.x <= 1.0 &&
      projectedTexcoord.y >= 0.0 &&
      projectedTexcoord.y <= 1.0;

  // the 'r' channel has the depth values
  float projectedDepth = texture(u_projectedTexture, projectedTexcoord.xy).r;
  float shadowLight = (inRange && projectedDepth <= currentDepth) ? 0.0 : 1.0;

  vec4 texColor = texture(u_texture, v_texcoord) * u_colorMult;
-  outColor = vec4(texColor.rgb * shadowLight, texColor.a);
+  outColor = vec4(
+      texColor.rgb * light * shadowLight +
+      specular * shadowLight,
+      texColor.a);
}
</code></pre>

<p>Notice we just use <code>shadowLight</code> to adjust the affect of the <code>light</code> and<br /><code>specular</code>. If an object is in shadow than there is no light.</p>

<p>We just need to set the uniforms </p>

<pre><code>
-function drawScene(projectionMatrix, cameraMatrix, textureMatrix, programInfo) {
+function drawScene(
+    projectionMatrix,
+    cameraMatrix,
+    textureMatrix,
+    lightWorldMatrix,
+    programInfo) {
  // Make a view matrix from the camera matrix.
  const viewMatrix = m4.inverse(cameraMatrix);

  gl.useProgram(programInfo.program);

  // set uniforms that are the same for both the sphere and plane
  // note: any values with no corresponding uniform in the shader
  // are ignored.
  twgl.setUniforms(programInfo, {
    u_view: viewMatrix,
    u_projection: projectionMatrix,
    u_bias: settings.bias,
    u_textureMatrix: textureMatrix,
    u_projectedTexture: depthTexture,
+    u_shininess: 150,
+    u_innerLimit: Math.cos(degToRad(settings.fieldOfView / 2 - 10)),
+    u_outerLimit: Math.cos(degToRad(settings.fieldOfView / 2)),
+    u_lightDirection: lightWorldMatrix.slice(8, 11).map(v => -v),
+    u_lightWorldPosition: lightWorldMatrix.slice(12, 15),
+    u_viewWorldPosition: cameraMatrix.slice(12, 15),
  });

...

function render() {
  ...

-  drawScene(lightProjectionMatrix, lightWorldMatrix, m4.identity(), colorProgramInfo);
+  drawScene(
+      lightProjectionMatrix,
+      lightWorldMatrix,
+      m4.identity(),
+      lightWorldMatrix,
+      colorProgramInfo);

  ...

-  drawScene(projectionMatrix, cameraMatrix, textureMatrix, textureProgramInfo);
+  drawScene(
+      projectionMatrix,
+      cameraMatrix,
+      textureMatrix,
+      lightWorldMatrix,
+      textureProgramInfo);

  ...
}
</code></pre>

<p>To go over a few of those uniform settings. Recall from the <a href="webgl-3d-lighting-spot.html">spot light article</a><br />the innerLimit and outerLimit settings are in dot space (cosine space) and that<br />we only need half the field of view since they extend around the direction of the light.<br />Also recall from <a href="webgl-3d-camera.html">the camera article</a> the 3rd row of 4x4 matrix<br />is the Z axis so pulling out the first 3 values of the 3rd row from the <code>lightWorldMatrix</code><br />gives us the -Z direction of the light. We want the positive direction so we flip it.<br />Similarly the same article tells us the 4th row is the world position so we can get<br />the lightWorldPosition and viewWorldPosition (also known as the camera world position)<br />by pulling them out of the their respective matrices. Of course we could have also<br />got them by exposing more settings or passing more variables.</p>

<p>Let's also clear the background to black and set the frustum lines to white</p>

<pre><code>
function render() {

  ...

  // now draw scene to the canvas projecting the depth texture into the scene
  gl.bindFramebuffer(gl.FRAMEBUFFER, null);
  gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
+  gl.clearColor(0, 0, 0, 1);
  gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

  ...

  // ------ Draw the frustum ------
  {

    ...

          // Set the uniforms we just computed
    twgl.setUniforms(colorProgramInfo, {
-      u_color: [0, 0, 0, 1],
+      u_color: [1, 1, 1, 1],
      u_view: viewMatrix,
      u_projection: projectionMatrix,
      u_world: mat,
    });
</code></pre>

<p>And now we have a spot light with shadows.</p>

<p>{{{example url="../webgl-shadows-w-spot-light.html" }}}</p>

<p>For a directional light we'd copy the shader code from<br /><a href="webgl-3d-lighting-directional.html">the article on directional lights</a><br />and change our projection from perspective to orthographic.</p>

<p>First the vertex shader</p>

<pre><code>
#version 300 es
in vec4 a_position;
in vec2 a_texcoord;
+in vec3 a_normal;

-uniform vec3 u_lightWorldPosition;
-uniform vec3 u_viewWorldPosition;

uniform mat4 u_projection;
uniform mat4 u_view;
uniform mat4 u_world;
uniform mat4 u_textureMatrix;

out vec2 v_texcoord;
out vec4 v_projectedTexcoord;
out vec3 v_normal;

-out vec3 v_surfaceToLight;
-out vec3 v_surfaceToView;

void main() {
  // Multiply the position by the matrix.
  vec4 worldPosition = u_world * a_position;

  gl_Position = u_projection * u_view * worldPosition;

  // Pass the texture coord to the fragment shader.
  v_texcoord = a_texcoord;

  v_projectedTexcoord = u_textureMatrix * worldPosition;

  // orient the normals and pass to the fragment shader
  v_normal = mat3(u_world) * a_normal;

-  // compute the world position of the surface
-  vec3 surfaceWorldPosition = (u_world * a_position).xyz;
-
-  // compute the vector of the surface to the light
-  // and pass it to the fragment shader
-  v_surfaceToLight = u_lightWorldPosition - surfaceWorldPosition;
-
-  // compute the vector of the surface to the view/camera
-  // and pass it to the fragment shader
-  v_surfaceToView = u_viewWorldPosition - surfaceWorldPosition;
}
</code></pre>

<p>Then the fragment shader</p>

<pre><code>
#version 300 es
precision highp float;

// Passed in from the vertex shader.
in vec2 v_texcoord;
in vec4 v_projectedTexcoord;
in vec3 v_normal;
-in vec3 v_surfaceToLight;
-in vec3 v_surfaceToView;

uniform vec4 u_colorMult;
uniform sampler2D u_texture;
uniform sampler2D u_projectedTexture;
uniform float u_bias;
-uniform float u_shininess;
-uniform vec3 u_lightDirection;
-uniform float u_innerLimit;          // in dot space
-uniform float u_outerLimit;          // in dot space
+uniform vec3 u_reverseLightDirection;

out vec4 outColor;

void main() {
  // because v_normal is a varying it's interpolated
  // so it will not be a unit vector. Normalizing it
  // will make it a unit vector again
  vec3 normal = normalize(v_normal);

+  float light = dot(normal, u_reverseLightDirection);

-  vec3 surfaceToLightDirection = normalize(v_surfaceToLight);
-  vec3 surfaceToViewDirection = normalize(v_surfaceToView);
-  vec3 halfVector = normalize(surfaceToLightDirection + surfaceToViewDirection);
-
-  float dotFromDirection = dot(surfaceToLightDirection,
-                               -u_lightDirection);
-  float limitRange = u_innerLimit - u_outerLimit;
-  float inLight = clamp((dotFromDirection - u_outerLimit) / limitRange, 0.0, 1.0);
-  float light = inLight * dot(normal, surfaceToLightDirection);
-  float specular = inLight * pow(dot(normal, halfVector), u_shininess);

  vec3 projectedTexcoord = v_projectedTexcoord.xyz / v_projectedTexcoord.w;
  float currentDepth = projectedTexcoord.z + u_bias;

  bool inRange =
      projectedTexcoord.x >= 0.0 &&
      projectedTexcoord.x <= 1.0 &&
      projectedTexcoord.y >= 0.0 &&
      projectedTexcoord.y <= 1.0;

  // the 'r' channel has the depth values
  float projectedDepth = texture(u_projectedTexture, projectedTexcoord.xy).r;
  float shadowLight = (inRange && projectedDepth <= currentDepth) ? 0.0 : 1.0;

  vec4 texColor = texture(u_texture, v_texcoord) * u_colorMult;
  outColor = vec4(
-      texColor.rgb * light * shadowLight +
-      specular * shadowLight,
+      texColor.rgb * light * shadowLight,
      texColor.a);
}
</code></pre>

<p>and the uniforms</p>

<pre><code>
  // set uniforms that are the same for both the sphere and plane
  // note: any values with no corresponding uniform in the shader
  // are ignored.
  twgl.setUniforms(programInfo, {
    u_view: viewMatrix,
    u_projection: projectionMatrix,
    u_bias: settings.bias,
    u_textureMatrix: textureMatrix,
    u_projectedTexture: depthTexture,
-    u_shininess: 150,
-    u_innerLimit: Math.cos(degToRad(settings.fieldOfView / 2 - 10)),
-    u_outerLimit: Math.cos(degToRad(settings.fieldOfView / 2)),
-    u_lightDirection: lightWorldMatrix.slice(8, 11).map(v => -v),
-    u_lightWorldPosition: lightWorldMatrix.slice(12, 15),
-    u_viewWorldPosition: cameraMatrix.slice(12, 15),
+    u_reverseLightDirection: lightWorldMatrix.slice(8, 11),
  });
</code></pre>

<p>I adjusted the camera to see more of the scene.</p>

<p>{{{example url="../webgl-shadows-w-directional-light.html"}}}</p>

<p>This points out something that should be obvious from the code above but our<br />shadow map is only so big so even though a directional light calculations<br />only have a direction, there is no position for the light itself, we still<br />have to choose a position in order to decide the area to compute and apply<br />the shadow map.</p>

<p>This article is getting long and there are still many things to cover related<br />to shadows so we'll leave the rest to <a href="webgl-shadows-continued.html">the next article</a>.</p>